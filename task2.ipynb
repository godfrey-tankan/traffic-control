{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba32dfb4-9cb4-427b-87b3-ed01ec7f9693",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Car Detection using OpenCV\n",
    "\n",
    "This code performs car detection using OpenCV. It allows you to either detect cars in real-time using a camera or analyze a video file.\n",
    "\n",
    "## Functionality\n",
    "\n",
    "1. **Input Source Selection**: The code prompts the user to enter the source type: `'camera'` for real-time camera detection or `'video'` to analyze a video file.\n",
    "   - If `'camera'` is selected, it captures video frames from the default camera (index 0).\n",
    "   - If `'video'` is selected, the user is asked to provide the path to the video file.\n",
    "\n",
    "2. **Video Capture**: The code initializes a `cv2.VideoCapture` object to read frames from the selected source.\n",
    "   - If the source is a camera, it opens the default camera.\n",
    "   - If the source is a video file, it opens the specified file.\n",
    "\n",
    "3. **Background Subtraction**: The code creates a background subtractor using `cv2.createBackgroundSubtractorMOG2`.\n",
    "   - This subtractor is used to separate moving objects (such as cars) from the background.\n",
    "   - The parameters `history`, `varThreshold`, and `detectShadows` control the behavior of the background subtractor.\n",
    "\n",
    "4. **Detection Loop**: The code enters a loop to process each frame from the video source.\n",
    "   - It reads the next frame using `cap.read()`.\n",
    "   - The background subtractor is applied to the frame, generating a binary mask that highlights moving objects.\n",
    "   - A binary threshold is applied to the mask to obtain a more distinct separation between the objects and the background.\n",
    "\n",
    "5. **Contour Detection**: The code uses `cv2.findContours` to detect contours in the binary mask.\n",
    "   - Contours are continuous curves that form the boundaries of the objects in the mask.\n",
    "   - The `cv2.RETR_TREE` retrieval mode and `cv2.CHAIN_APPROX_SIMPLE` contour approximation method are used.\n",
    "\n",
    "6. **Car Detection**: The code iterates over the detected contours and applies a size threshold to identify car-like objects.\n",
    "   - If the contour area is greater than or equal to 5000 pixels, it is considered a car.\n",
    "   - A bounding rectangle is drawn around each detected car using `cv2.rectangle`.\n",
    "\n",
    "7. **Display**: The code displays the processed frame with the bounding rectangles using `cv2.imshow`.\n",
    "\n",
    "8. **Termination**: The code waits for a key press using `cv2.waitKey`. If the 'Esc' key is pressed (key code 27), the loop is terminated.\n",
    "\n",
    "9. **Cleanup**: After the loop, the video source is released using `cap.release()`, and all windows are closed using `cv2.destroyAllWindows()`.\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Run the code in a Python environment that has OpenCV installed.\n",
    "\n",
    "2. Follow the prompts to select the source type and, if applicable, enter the path to the video file.\n",
    "\n",
    "3. The code will start processing the frames and display the output in a separate window.\n",
    "\n",
    "4. To exit the program, press the 'Esc' key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8eaf84f-afc6-4c2c-a8ca-882ac57e7001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tracker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e993b54-9f9c-4a72-bd07-1721d12aa5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('task1/test2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f1332f-faba-4688-8718-79774b8dd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_tracker_ob = EuclideanDistTracker()\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50, detectShadows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa56370-381b-4efa-857f-dd997fce0e39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 3\u001b[0m     roi \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m690\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m     mask \u001b[38;5;241m=\u001b[39m object_detector\u001b[38;5;241m.\u001b[39mapply(roi)\n\u001b[1;32m      6\u001b[0m     _, mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(mask, \u001b[38;5;241m254\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    roi = frame[200:-100, 300:-690]\n",
    "   \n",
    "    mask = object_detector.apply(roi)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    contours,_ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detected_cars = []\n",
    "    for cnt in contours:\n",
    "        # cv2.drawContours(frame, [cnt], -1, (0, 255, 0), 2)\n",
    "        if cv2.contourArea(cnt) > 5000:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            detected_object = [x, y, w, h]\n",
    "            if detected_object not in detected_cars:\n",
    "                detected_cars.append([x, y, w, h])\n",
    "    cars_tracked = car_tracker_ob.update(detected_cars)\n",
    "\n",
    "    for car in cars_tracked:\n",
    "        x, y, w, h, id = car\n",
    "        cv2.putText(roi,str(id), (x, y-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.rectangle(roi, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "    # cv2.imshow('Frame', roi)\n",
    "    cv2.imshow('Frame', frame)\n",
    "    # cv2.imshow('Mask', mask)\n",
    "\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced47770-4a36-436a-a011-7825e953c483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
