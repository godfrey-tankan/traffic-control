{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba32dfb4-9cb4-427b-87b3-ed01ec7f9693",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Car Detection,Tracking and Counting using OpenCV\n",
    "\n",
    "This code performs car detection using OpenCV. It allows you to either detect cars in real-time using a camera or analyze a video file.\n",
    "\n",
    "## Functionality\n",
    "\n",
    "1. **Input Source Selection**: The code prompts the user to enter the source type: `'camera'` for real-time camera detection or `'video'` to analyze a video file.\n",
    "   - If `'camera'` is selected, it captures video frames from the default camera (index 0).\n",
    "   - If `'video'` is selected, the user is asked to provide the path to the video file.\n",
    "\n",
    "2. **Video Capture**: The code initializes a `cv2.VideoCapture` object to read frames from the selected source.\n",
    "   - If the source is a camera, it opens the default camera.\n",
    "   - If the source is a video file, it opens the specified file.\n",
    "\n",
    "3. **Background Subtraction**: The code creates a background subtractor using `cv2.createBackgroundSubtractorMOG2`.\n",
    "   - This subtractor is used to separate moving objects (such as cars) from the background.\n",
    "   - The parameters `history`, `varThreshold`, and `detectShadows` control the behavior of the background subtractor.\n",
    "\n",
    "4. **Detection Loop**: The code enters a loop to process each frame from the video source.\n",
    "   - It reads the next frame using `cap.read()`.\n",
    "   - The background subtractor is applied to the frame, generating a binary mask that highlights moving objects.\n",
    "   - A binary threshold is applied to the mask to obtain a more distinct separation between the objects and the background.\n",
    "\n",
    "5. **Contour Detection**: The code uses `cv2.findContours` to detect contours in the binary mask.\n",
    "   - Contours are continuous curves that form the boundaries of the objects in the mask.\n",
    "   - The `cv2.RETR_TREE` retrieval mode and `cv2.CHAIN_APPROX_SIMPLE` contour approximation method are used.\n",
    "\n",
    "6. **Car Detection**: The code iterates over the detected contours and applies a size threshold to identify car-like objects.\n",
    "   - If the contour area is greater than or equal to 5000 pixels, it is considered a car.\n",
    "   - A bounding rectangle is drawn around each detected car using `cv2.rectangle`.\n",
    "\n",
    "7. **Display**: The code displays the processed frame with the bounding rectangles using `cv2.imshow`.\n",
    "\n",
    "8. **Termination**: The code waits for a key press using `cv2.waitKey`. If the 'Esc' key is pressed (key code 27), the loop is terminated.\n",
    "\n",
    "9. **Cleanup**: After the loop, the video source is released using `cap.release()`, and all windows are closed using `cv2.destroyAllWindows()`.\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Run the code in a Python environment that has OpenCV installed. by running command : **jupyter notebook**\n",
    "\n",
    "A browser will open and choose **task2.ipynb**\n",
    "Use a double **foward arrow** before the  **code** select box  or run all the cells manually from the top by using **shift + Enter** Keys\n",
    "Scroll all the way down to choose detection type **camera or video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8eaf84f-afc6-4c2c-a8ca-882ac57e7001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tracker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa56370-381b-4efa-857f-dd997fce0e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 'camera' for camera detection or 'video' for video upload:  video\n",
      "Enter the path to the video file or Enter to use available video:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/tnqn/Documents/personal/detecting_cars/env/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 23\u001b[0m     roi \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m690\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m     mask \u001b[38;5;241m=\u001b[39m object_detector\u001b[38;5;241m.\u001b[39mapply(roi)\n\u001b[1;32m     26\u001b[0m     _, mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(mask, \u001b[38;5;241m254\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    source_type = input(\"Enter 'camera' for camera detection or 'video' for video upload: \")\n",
    "    object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50, detectShadows=100)\n",
    "    car_tracker_ob = EuclideanDistTracker()\n",
    "    if source_type.lower() == 'camera':\n",
    "        cap = cv2.VideoCapture(0) \n",
    "        cap.read()\n",
    "    elif source_type.lower() == 'video':\n",
    "        video_path = input(\"Enter the path to the video file or Enter to use available video: \")\n",
    "        print(\"path: \", video_path)\n",
    "        path =\"video/test2.mp4\"\n",
    "        cap = cv2.VideoCapture(path)\n",
    "    else:\n",
    "        print(\"Invalid input. Exiting...\")\n",
    "        return\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Failed to open the video source. Exiting...\")\n",
    "        return\n",
    "    car_count = 0  # Initialize car count\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        roi = frame[200:-100, 300:-690]\n",
    "       \n",
    "        mask = object_detector.apply(roi)\n",
    "        _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        detected_cars = []\n",
    "        for cnt in contours:\n",
    "            if cv2.contourArea(cnt) > 5000:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                detected_object = [x, y, w, h]\n",
    "                if detected_object not in detected_cars:\n",
    "                    detected_cars.append([x, y, w, h])\n",
    "                      # Increment car count\n",
    "    \n",
    "        cars_tracked = car_tracker_ob.update(detected_cars)\n",
    "    \n",
    "        for car in cars_tracked:\n",
    "            x, y, w, h, id = car\n",
    "            \n",
    "            car_count = id\n",
    "            cv2.rectangle(roi, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "        \n",
    "        cv2.putText(frame, f\"Counted Cars: {car_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    \n",
    "        cv2.imshow('Frame', frame)\n",
    "    \n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced47770-4a36-436a-a011-7825e953c483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
